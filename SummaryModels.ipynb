{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e7d82f3",
   "metadata": {},
   "source": [
    "# K-nearest neighbor (KNN)\n",
    "* A **non-parametric** model\n",
    "* A **non-linear** model\n",
    "\n",
    "It makes few assumptions about structure of data and usually gives accurate result, but it is unstable to small changes in the dataset.\n",
    "\n",
    "* Classifier\n",
    "* Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fce6fa",
   "metadata": {},
   "source": [
    "Instance based or memory based supervised learning.\n",
    "\n",
    "- KNN classifier: memorize the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdfa448",
   "metadata": {},
   "source": [
    "Four things should be specified:\n",
    "\n",
    "    1) A distance metric.\n",
    "        * it controls the distance function between points and thus which points are considered as nearest in finding neighbors.\n",
    "        * Typically Euclidean (Minkowski with p = 2)\n",
    "    2) How many nearest neighbors to look at? (Model complexity)\n",
    "        * k=5\n",
    "    3) Optional weighting function on the neighbor points.\n",
    "        * Ignored\n",
    "    4) Methods for aggregating the classes of neighbor points.\n",
    "        * Majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca618c9",
   "metadata": {},
   "source": [
    "### Relation between k and model complexity\n",
    "\n",
    "* **Reducing k** in knn classifier **increases** the variance of the decision boundries and the risk of **Overfitting** because very local changes is captured.\n",
    "\n",
    "* **k=the total number** of points in the training set, the result would be a **single decision** which it is the **most frequent** calss in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d319428",
   "metadata": {},
   "source": [
    "### Drawback:\n",
    "\n",
    "When the training data has many samples, or each sample has lots of features, this can slow down the performance of KNN model.\n",
    "\n",
    "For data set with hundred of thousands of features, especially if it is sparse, we should apply another model in stead of KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fdb4c4",
   "metadata": {},
   "source": [
    "# Linear regression:\n",
    "\n",
    "A **parametric** model. It assumes a linear relationship between the input variables (features) and the single output variable (target).\n",
    "\n",
    " It gives the target based on weighted sum of the features. The task of machine learning is to find the weighting parameters based on the previous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36427ac0",
   "metadata": {},
   "source": [
    "**Least square linear regression** (AKA: ordinary least square)\n",
    "\n",
    "* It minimize the mean square error between target and prediction to find ws(weights) and b (bias/intercept parameter)\n",
    "\n",
    " $RSS(w,b) = \\sum_{i=1}^N (y_i - (w.x_i + b))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6959b",
   "metadata": {},
   "source": [
    "**Implementation in Sklearn**:\n",
    "\n",
    "* $w$ : linreg.coef_\n",
    "\n",
    "* $b$: linreg.intercept_\n",
    "\n",
    "    -The ' _ ' in linreg.coef_ means it is a parameter that has been derived by training the data and it is not set by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cc17c",
   "metadata": {},
   "source": [
    "## Comparing between KNN and Linear regression:\n",
    "\n",
    "* **KNN**:\n",
    "    - does not make a lot of assumption about the structure of the data.\n",
    "    - gives potentially accurate but sometimes unstable predictions that are sensitive to small changes in the training data.\n",
    "    - better on training set.\n",
    "\n",
    "* **Linear regression**:\n",
    "    - makes strong assuptions about the structure of the data: linear relationship.\n",
    "    - gives stable but potentially inaccurate predictions.\n",
    "    - better on unseen data.\n",
    "    - very extendable to new data beyond the training set.\n",
    "    - no parameter to control the complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d4049",
   "metadata": {},
   "source": [
    "# Regularization:\n",
    "Regularization prevents **overfitting** by restricting the model typically to reduce its complexity. \n",
    "\n",
    "* Ridge regression (L2)\n",
    "* Lasso regression (L1)\n",
    "\n",
    "### Ridge regression:\n",
    "\n",
    "Using same least-square criterion but adds a penalty for **large variations** in weight parameters.\n",
    "\n",
    "$RSS_{ridge}(w,b) = \\sum_{i=1}^N (y_i - (w.x_i+b))^2 + \\alpha \\sum_{i=1}^P w_j^2$\n",
    "\n",
    "**Higher** $\\alpha$ means **more** regularization and **simpler** models.\n",
    "\n",
    "### Lasso regression:\n",
    "\n",
    "Like Ridge regression, a regullarization penalty term to the ordinary RSS that cause w coefficients to shrink toward zero.\n",
    "\n",
    "$RSS_{lasso}(w,b) = \\sum_{i=1}^N (y_i - (w.x_i+b))^2 + \\alpha \\sum_{i=1}^P |w_j|$\n",
    "\n",
    "With lasso, a subset of the coefficients are forced to be precisely zero. (it is called sparse solution which is a kind of **Feature selection**)\n",
    "\n",
    "By default $\\alpha=0$.\n",
    "\n",
    "\n",
    "### Use\n",
    "* **Ridge**: Many small/Medium sized effects.\n",
    "* **Lasso**: Only a few variables with medium effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6ec26",
   "metadata": {},
   "source": [
    "# Polynomial Features:\n",
    "\n",
    "Generate polynomial and interaction features.\n",
    "\n",
    "* It is still a **linear** model.\n",
    "* Polynomial feature expansion is often combined with a regularization learning method like ridge regression.\n",
    "* Using higher degrees leads to more complex models and regularization might be needed to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2f36b",
   "metadata": {},
   "source": [
    "# Linear model for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90293c",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "* Linear model\n",
    "* default: Binary classification but can be applied on multi-class \n",
    "* Applying logistic function (activation function) on estimated probabilities determines the class\n",
    "* Parameter $C$ controls **regularization**\n",
    "    - default: $C = 1$ Ridge (L2) regularization\n",
    "    - **Higher** $C$ corresponds to **less** regularization\n",
    "* Normalization woud be important here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad58a2f",
   "metadata": {},
   "source": [
    "# Support vector machine (SVM):\n",
    "\n",
    "* Apply **sign function** as activation function to produce binary output\n",
    "    -feature vector -> linear function: $Sign(w.x+b)$ -> class value\n",
    "* **Classifier margin** is defined as the width the decision boundary area can be increased before hitting a data point.\n",
    "* The **best** classifier has the **maximum** margin.\n",
    "* The **maximum** margin classifier is called the **linear support vector machine (LSVM)**\n",
    "* Parameter $C$ controls **regularization**\n",
    "    - default: $C = 1$ Ridge (L2) regularization\n",
    "    - **Higher** $C$ corresponds to **less** regularization.\n",
    "        * Fit the training data as well as possible\n",
    "        * Each individual data point is important to classify correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208effc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
